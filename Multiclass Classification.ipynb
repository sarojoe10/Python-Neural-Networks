{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 08:18:42.520583: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-04 08:18:42.557281: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-04 08:18:42.557310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-04 08:18:42.558080: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-04 08:18:42.564396: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-04 08:18:43.225628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 367,\n",
       " 1394,\n",
       " 169,\n",
       " 65,\n",
       " 87,\n",
       " 209,\n",
       " 30,\n",
       " 306,\n",
       " 228,\n",
       " 10,\n",
       " 803,\n",
       " 305,\n",
       " 96,\n",
       " 5,\n",
       " 196,\n",
       " 15,\n",
       " 10,\n",
       " 523,\n",
       " 2,\n",
       " 3006,\n",
       " 293,\n",
       " 484,\n",
       " 2,\n",
       " 1440,\n",
       " 5825,\n",
       " 8,\n",
       " 145,\n",
       " 7,\n",
       " 10,\n",
       " 1670,\n",
       " 6,\n",
       " 10,\n",
       " 294,\n",
       " 517,\n",
       " 237,\n",
       " 2,\n",
       " 367,\n",
       " 8042,\n",
       " 7,\n",
       " 2477,\n",
       " 1177,\n",
       " 483,\n",
       " 1440,\n",
       " 5825,\n",
       " 8,\n",
       " 367,\n",
       " 1394,\n",
       " 4,\n",
       " 169,\n",
       " 387,\n",
       " 66,\n",
       " 209,\n",
       " 30,\n",
       " 2344,\n",
       " 652,\n",
       " 1496,\n",
       " 9,\n",
       " 209,\n",
       " 30,\n",
       " 2564,\n",
       " 228,\n",
       " 10,\n",
       " 803,\n",
       " 305,\n",
       " 96,\n",
       " 5,\n",
       " 196,\n",
       " 15,\n",
       " 51,\n",
       " 36,\n",
       " 1457,\n",
       " 24,\n",
       " 1345,\n",
       " 5,\n",
       " 4,\n",
       " 196,\n",
       " 150,\n",
       " 10,\n",
       " 523,\n",
       " 320,\n",
       " 64,\n",
       " 992,\n",
       " 6373,\n",
       " 13,\n",
       " 367,\n",
       " 190,\n",
       " 297,\n",
       " 64,\n",
       " 85,\n",
       " 1692,\n",
       " 6,\n",
       " 8656,\n",
       " 122,\n",
       " 9,\n",
       " 36,\n",
       " 1457,\n",
       " 24,\n",
       " 269,\n",
       " 4753,\n",
       " 27,\n",
       " 367,\n",
       " 212,\n",
       " 114,\n",
       " 45,\n",
       " 30,\n",
       " 3292,\n",
       " 7,\n",
       " 126,\n",
       " 2203,\n",
       " 13,\n",
       " 367,\n",
       " 6,\n",
       " 1818,\n",
       " 4,\n",
       " 169,\n",
       " 65,\n",
       " 96,\n",
       " 28,\n",
       " 432,\n",
       " 23,\n",
       " 189,\n",
       " 1254,\n",
       " 4,\n",
       " 9725,\n",
       " 320,\n",
       " 5,\n",
       " 196,\n",
       " 15,\n",
       " 10,\n",
       " 523,\n",
       " 25,\n",
       " 730,\n",
       " 190,\n",
       " 57,\n",
       " 64,\n",
       " 6,\n",
       " 9953,\n",
       " 2016,\n",
       " 6373,\n",
       " 7,\n",
       " 2,\n",
       " 122,\n",
       " 1440,\n",
       " 5825,\n",
       " 8,\n",
       " 269,\n",
       " 4753,\n",
       " 1217,\n",
       " 7,\n",
       " 608,\n",
       " 2203,\n",
       " 30,\n",
       " 3292,\n",
       " 1440,\n",
       " 5825,\n",
       " 8,\n",
       " 43,\n",
       " 339,\n",
       " 43,\n",
       " 231,\n",
       " 9,\n",
       " 667,\n",
       " 1820,\n",
       " 126,\n",
       " 212,\n",
       " 4197,\n",
       " 21,\n",
       " 1709,\n",
       " 249,\n",
       " 311,\n",
       " 13,\n",
       " 260,\n",
       " 489,\n",
       " 9,\n",
       " 65,\n",
       " 4753,\n",
       " 64,\n",
       " 1209,\n",
       " 4397,\n",
       " 249,\n",
       " 954,\n",
       " 36,\n",
       " 152,\n",
       " 1440,\n",
       " 5825,\n",
       " 506,\n",
       " 24,\n",
       " 135,\n",
       " 367,\n",
       " 311,\n",
       " 34,\n",
       " 420,\n",
       " 4,\n",
       " 8407,\n",
       " 200,\n",
       " 1519,\n",
       " 13,\n",
       " 137,\n",
       " 730,\n",
       " 190,\n",
       " 7,\n",
       " 104,\n",
       " 570,\n",
       " 52,\n",
       " 64,\n",
       " 2492,\n",
       " 7725,\n",
       " 4,\n",
       " 642,\n",
       " 5,\n",
       " 405,\n",
       " 7725,\n",
       " 2492,\n",
       " 24,\n",
       " 76,\n",
       " 847,\n",
       " 1435,\n",
       " 4446,\n",
       " 6,\n",
       " 10,\n",
       " 548,\n",
       " 320,\n",
       " 34,\n",
       " 325,\n",
       " 136,\n",
       " 694,\n",
       " 1440,\n",
       " 5825,\n",
       " 8,\n",
       " 10,\n",
       " 5184,\n",
       " 847,\n",
       " 7,\n",
       " 4,\n",
       " 169,\n",
       " 76,\n",
       " 2378,\n",
       " 10,\n",
       " 4933,\n",
       " 3447,\n",
       " 5,\n",
       " 141,\n",
       " 1082,\n",
       " 36,\n",
       " 152,\n",
       " 36,\n",
       " 8,\n",
       " 126,\n",
       " 358,\n",
       " 367,\n",
       " 65,\n",
       " 814,\n",
       " 190,\n",
       " 64,\n",
       " 2575,\n",
       " 10,\n",
       " 969,\n",
       " 3161,\n",
       " 92,\n",
       " 48,\n",
       " 6,\n",
       " 2245,\n",
       " 31,\n",
       " 367,\n",
       " 51,\n",
       " 570,\n",
       " 4753,\n",
       " 292,\n",
       " 27,\n",
       " 405,\n",
       " 212,\n",
       " 62,\n",
       " 3740,\n",
       " 922,\n",
       " 9,\n",
       " 2464,\n",
       " 27,\n",
       " 367,\n",
       " 77,\n",
       " 62,\n",
       " 4397,\n",
       " 7,\n",
       " 316,\n",
       " 5,\n",
       " 874,\n",
       " 36,\n",
       " 152,\n",
       " 4,\n",
       " 936,\n",
       " 1243,\n",
       " 5,\n",
       " 358,\n",
       " 367,\n",
       " 398,\n",
       " 57,\n",
       " 45,\n",
       " 3680,\n",
       " 7367,\n",
       " 6,\n",
       " 2394,\n",
       " 1343,\n",
       " 13,\n",
       " 373,\n",
       " 4504,\n",
       " 36,\n",
       " 8,\n",
       " 1440,\n",
       " 5825,\n",
       " 8,\n",
       " 42,\n",
       " 196,\n",
       " 150,\n",
       " 10,\n",
       " 523,\n",
       " 96,\n",
       " 34,\n",
       " 9725,\n",
       " 43,\n",
       " 16,\n",
       " 1261,\n",
       " 205,\n",
       " 7,\n",
       " 4,\n",
       " 65,\n",
       " 182,\n",
       " 1351,\n",
       " 367,\n",
       " 6,\n",
       " 351,\n",
       " 184,\n",
       " 45,\n",
       " 6081,\n",
       " 2286,\n",
       " 197,\n",
       " 1245,\n",
       " 13,\n",
       " 3187,\n",
       " 2,\n",
       " 274,\n",
       " 419,\n",
       " 714,\n",
       " 1351,\n",
       " 367,\n",
       " 269,\n",
       " 10,\n",
       " 96,\n",
       " 41,\n",
       " 129,\n",
       " 1104,\n",
       " 1673,\n",
       " 1419,\n",
       " 578,\n",
       " 36,\n",
       " 152,\n",
       " 2,\n",
       " 1440,\n",
       " 7615,\n",
       " 367,\n",
       " 1683,\n",
       " 484,\n",
       " 293,\n",
       " 75,\n",
       " 6557,\n",
       " 4,\n",
       " 8042,\n",
       " 152,\n",
       " 24,\n",
       " 5222,\n",
       " 34,\n",
       " 325,\n",
       " 834,\n",
       " 6,\n",
       " 1356,\n",
       " 2,\n",
       " 2406,\n",
       " 7,\n",
       " 4,\n",
       " 65,\n",
       " 76,\n",
       " 1082,\n",
       " 164,\n",
       " 1574,\n",
       " 212,\n",
       " 9,\n",
       " 861,\n",
       " 34,\n",
       " 8340,\n",
       " 13,\n",
       " 286,\n",
       " 1930,\n",
       " 1440,\n",
       " 7615,\n",
       " 8,\n",
       " 787,\n",
       " 36,\n",
       " 1830,\n",
       " 1082,\n",
       " 41,\n",
       " 3751,\n",
       " 616,\n",
       " 6,\n",
       " 382,\n",
       " 2,\n",
       " 2,\n",
       " 1574,\n",
       " 6928,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequence(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequence(train_data)\n",
    "x_test = vectorize_sequence(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "#This is built-in way to do this in Keras as:\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "# one_hot_train_labels = to_categorical(train_labels)\n",
    "# one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:18:18.727771: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-04 19:18:18.842454: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "#Using softmax activation function means network will output probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 30ms/step - loss: 2.7963 - accuracy: 0.4449 - val_loss: 1.9006 - val_accuracy: 0.6220\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5436 - accuracy: 0.6822 - val_loss: 1.3713 - val_accuracy: 0.6930\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.1523 - accuracy: 0.7463 - val_loss: 1.1816 - val_accuracy: 0.7320\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.9366 - accuracy: 0.7970 - val_loss: 1.0970 - val_accuracy: 0.7650\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.7801 - accuracy: 0.8338 - val_loss: 1.0256 - val_accuracy: 0.7760\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.6491 - accuracy: 0.8626 - val_loss: 0.9734 - val_accuracy: 0.7930\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.5439 - accuracy: 0.8817 - val_loss: 0.9201 - val_accuracy: 0.7990\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4591 - accuracy: 0.9003 - val_loss: 0.9028 - val_accuracy: 0.8070\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3870 - accuracy: 0.9164 - val_loss: 0.9032 - val_accuracy: 0.8040\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.3308 - accuracy: 0.9281 - val_loss: 0.8947 - val_accuracy: 0.8160\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2855 - accuracy: 0.9367 - val_loss: 0.8792 - val_accuracy: 0.8140\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2484 - accuracy: 0.9449 - val_loss: 0.9206 - val_accuracy: 0.8020\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.2213 - accuracy: 0.9466 - val_loss: 0.8910 - val_accuracy: 0.8190\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1982 - accuracy: 0.9494 - val_loss: 0.8978 - val_accuracy: 0.8140\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.1831 - accuracy: 0.9509 - val_loss: 0.9017 - val_accuracy: 0.8180\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1666 - accuracy: 0.9539 - val_loss: 0.9270 - val_accuracy: 0.8060\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1573 - accuracy: 0.9545 - val_loss: 0.9211 - val_accuracy: 0.8120\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1474 - accuracy: 0.9557 - val_loss: 0.9381 - val_accuracy: 0.8160\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1409 - accuracy: 0.9549 - val_loss: 0.9706 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1312 - accuracy: 0.9588 - val_loss: 0.9603 - val_accuracy: 0.8150\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512,\n",
    "                          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = trained_model.history['loss']\n",
    "val_loss = trained_model.history['val_loss']\n",
    "\n",
    "epochs = range(1, len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
